---
library_name: transformers
tags:
- unsloth
license: afl-3.0
language:
- ko
base_model:
- google/gemma-2-2b
pipeline_tag: question-answering
---

# Model Card for Model ID

<!-- Provide a quick summary of what the model is/does. -->



## Model Details

### Model Description

<!-- Provide a longer summary of what this model is. -->

This is the model card of a ðŸ¤— transformers model that has been pushed on the Hub. This model card has been automatically generated.

- **Developed by:** SJ Lee, YJ Kim, SH Kim
- **Activity with:** GMLB 2024, Gemma Sprint
- **Language(s) (NLP):** Korean
- **Finetuned from model [optional]:** google/gemma2-2b

### References

<!-- Provide the basic links for the model. -->

- **References:** https://colab.research.google.com/drive/1weTpKOjBZxZJ5PQ-Ql8i6ptAY2x-FWVA?usp=sharing
- **References:** https://www.sktenterprise.com/bizInsight/blogDetail/dev/9480

## Uses

<!-- Address questions around how the model is intended to be used, including the foreseeable users of the model and those affected by the model. -->

### Direct Use

<!-- This section is for the model use without fine-tuning or plugging into a larger ecosystem/app. -->

[More Information Needed]

### Data Resource
https://www.aihub.or.kr/aihubdata/data/view.do?currMenu=115&topMenu=100&aihubDataSe=data&dataSetSn=71776
<!-- This section is for the model use when fine-tuned for a task, or when plugged into a larger ecosystem/app -->

## How to Get Started with the Model

Use the code below to get started with the model.

[More Information Needed]

## Training Details
Gemma2 2B + Lora Finetuning
### Training Data
train.csv
<!-- This should link to a Dataset Card, perhaps with a short stub of information on what the training data is all about as well as documentation related to data pre-processing or additional filtering. -->

